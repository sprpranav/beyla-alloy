
\# ğŸš€ \*\*COMPLETE GUIDE: Beyla Observability Setup on Kubeadm 3-Node Cluster\*\*

\## ğŸ“‹ \*\*BEFORE YOU START - What You Have\*\*

\- âœ… Master Node: Dockerfile, grafana-deployment.yml, myapp-1.0.0.jar, myapp.tar, tempo-deployment.yml

\- âœ… Worker Nodes: myapp.tar file

\- âŒ Fresh Ubuntu VMs with nothing installed

\---

\## ğŸŒ \*\*NETWORK DIAGRAM\*\*

\`\`\`

\[GCP External\] â†’ \[Master Node\] â†’ \[Worker 1: App + Beyla\]

â†“ â†“ \[Worker 2: App + Beyla\]

Grafana \[Tempo + Calico\]

â†‘

\[Traces/Metrics\]

\`\`\`

\---

\## â±ï¸ \*\*ESTIMATED TIME: 45-60 minutes\*\*

\---

\# ğŸ¯ \*\*PHASE 1: SETUP ALL 3 NODES\*\*

\## \*\*Step 1.1: On ALL 3 NODES (Master, Worker1, Worker2)\*\*

\`\`\`bash

\# SSH to each node and run these

\# 1. Update system

sudo apt update

sudo apt upgrade -y

\# 2. Install Docker

sudo apt install -y docker.io

sudo systemctl enable docker

sudo systemctl start docker

\# 3. Add Docker to user group

sudo usermod -aG docker $USER

newgrp docker

\# 4. Disable swap

sudo swapoff -a

sudo sed -i '/ swap / s/^\\(.\*\\)$/#\\1/g' /etc/fstab

\# 5. Load kernel modules

sudo modprobe overlay

sudo modprobe br\_netfilter

\# 6. Set sysctl parameters

sudo tee /etc/sysctl.d/kubernetes.conf <<EOF

net.bridge.bridge-nf-call-ip6tables = 1

net.bridge.bridge-nf-call-iptables = 1

net.ipv4.ip\_forward = 1

EOF

sudo sysctl --system

\`\`\`

\## \*\*Step 1.2: Install Kubernetes on ALL 3 NODES\*\*

\`\`\`bash

\# 1. Add Kubernetes repo

curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -

sudo apt-add-repository "deb https://apt.kubernetes.io/ kubernetes-xenial main"

\# 2. Install kubelet, kubeadm, kubectl

sudo apt update

sudo apt install -y kubelet kubeadm kubectl

sudo apt-mark hold kubelet kubeadm kubectl

\# 3. Enable kubelet

sudo systemctl enable kubelet

\`\`\`

\---

\# ğŸ¯ \*\*PHASE 2: INITIALIZE MASTER NODE\*\*

\## \*\*Step 2.1: ONLY on MASTER NODE\*\*

\`\`\`bash

\# 1. Initialize Kubernetes cluster with Calico CIDR

sudo kubeadm init --pod-network-cidr=192.168.0.0/16

\# 2. After completion, you'll see a SUCCESS message

\# SAVE THE JOIN COMMAND! It looks like:

\# kubeadm join 10.160.0.X:6443 --token abcdef.1234567890abcdef \\

\# --discovery-token-ca-cert-hash sha256:...

\`\`\`

\## \*\*Step 2.2: Configure kubectl on MASTER\*\*

\`\`\`bash

\# 1. Setup kubectl config

mkdir -p $HOME/.kube

sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config

sudo chown $(id -u):$(id -g) $HOME/.kube/config

\# 2. Verify

kubectl get nodes # Should show master as NotReady

\`\`\`

\## \*\*Step 2.3: Install Calico CNI on MASTER\*\*

\`\`\`bash

\# 1. Install Calico

kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/tigera-operator.yaml

kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/custom-resources.yaml

\# 2. Wait 2 minutes

echo "Waiting for Calico to initialize..."

sleep 120

\# 3. Check Calico

kubectl get pods -n calico-system

\`\`\`

\---

\# ğŸ¯ \*\*PHASE 3: JOIN WORKER NODES\*\*

\## \*\*Step 3.1: Prepare Worker Nodes\*\*

\`\`\`bash

\# On EACH WORKER NODE (Worker1, Worker2):

\# 1. Load your app image

sudo docker load -i myapp.tar

\# 2. Pull required images in advance

sudo docker pull grafana/beyla:latest

sudo docker pull busybox:latest

\`\`\`

\## \*\*Step 3.2: Join Workers to Cluster\*\*

\`\`\`bash

\# 1. Get join command from MASTER

\# On MASTER, run:

kubeadm token create --print-join-command

\# 2. Copy the output command, then on EACH WORKER, run it:

\# Example (USE YOUR ACTUAL COMMAND):

sudo kubeadm join 10.160.0.X:6443 --token YOUR\_TOKEN \\

\--discovery-token-ca-cert-hash sha256:YOUR\_HASH

\`\`\`

\## \*\*Step 3.3: Verify on MASTER\*\*

\`\`\`bash

\# After joining both workers, check

kubectl get nodes

\# Should show:

\# NAME STATUS ROLES AGE VERSION

\# k8s-master Ready control-plane 5m v1.28.x

\# k8s-worker1 Ready <none> 1m v1.28.x

\# k8s-worker2 Ready <none> 1m v1.28.x

\`\`\`

\---

\# ğŸ¯ \*\*PHASE 4: DEPLOY OBSERVABILITY STACK\*\*

\## \*\*Step 4.1: Create Namespace\*\*

\`\`\`bash

\# On MASTER node

kubectl create namespace beyla

\`\`\`

\## \*\*Step 4.2: Build Your App Image\*\*

\`\`\`bash

\# On MASTER node

cd ~ # Go to where your Dockerfile is

\# 1. Build image

docker build -t myapp:latest .

\# 2. Save and copy to workers (optional, already done)

docker save myapp:latest -o myapp-new.tar

\# 3. Copy to workers if needed

\# scp myapp-new.tar worker1:~

\# scp myapp-new.tar worker2:~

\`\`\`

\## \*\*Step 4.3: Deploy Tempo (Traces)\*\*

\`\`\`bash

\# 1. Create tempo-deployment.yml if not exists

cat > tempo-deployment.yml << 'EOF'

apiVersion: apps/v1

kind: Deployment

metadata:

name: tempo

namespace: beyla

spec:

replicas: 1

selector:

matchLabels:

app: tempo

template:

metadata:

labels:

app: tempo

spec:

containers:

\- name: tempo

image: grafana/tempo:2.3.0

args: \["-config.file=/etc/tempo.yaml"\]

ports:

\- containerPort: 3200

\- containerPort: 4317

volumeMounts:

\- name: config

mountPath: /etc/tempo.yaml

subPath: tempo.yaml

volumes:

\- name: config

configMap:

name: tempo-config

\---

apiVersion: v1

kind: ConfigMap

metadata:

name: tempo-config

namespace: beyla

data:

tempo.yaml: |

server:

http\_listen\_port: 3200

grpc\_listen\_port: 9095

distributor:

receivers:

otlp:

protocols:

grpc:

ingester:

max\_block\_duration: 5m

compactor:

compaction:

block\_retention: 1h

storage:

trace:

backend: local

local:

path: /tmp/tempo

wal:

path: /tmp/tempo/wal

\---

apiVersion: v1

kind: Service

metadata:

name: tempo

namespace: beyla

spec:

selector:

app: tempo

ports:

\- name: http

port: 3200

targetPort: 3200

\- name: otlp-grpc

port: 4317

targetPort: 4317

type: ClusterIP

EOF

\# 2. Apply

kubectl apply -f tempo-deployment.yml

\`\`\`

\## \*\*Step 4.4: Deploy Grafana\*\*

\`\`\`bash

\# 1. Create grafana-deployment.yml if not exists

cat > grafana-deployment.yml << 'EOF'

apiVersion: apps/v1

kind: Deployment

metadata:

name: grafana

namespace: beyla

spec:

replicas: 1

selector:

matchLabels:

app: grafana

template:

metadata:

labels:

app: grafana

spec:

containers:

\- name: grafana

image: grafana/grafana:latest

ports:

\- containerPort: 3000

env:

\- name: GF\_SECURITY\_ADMIN\_PASSWORD

value: "admin"

volumeMounts:

\- name: grafana-storage

mountPath: /var/lib/grafana

volumes:

\- name: grafana-storage

emptyDir: {}

\---

apiVersion: v1

kind: Service

metadata:

name: grafana

namespace: beyla

spec:

selector:

app: grafana

ports:

\- port: 3000

targetPort: 3000

type: NodePort

EOF

\# 2. Apply

kubectl apply -f grafana-deployment.yml

\`\`\`

\---

\# ğŸ¯ \*\*PHASE 5: DEPLOY YOUR APP WITH BEYLA\*\*

\## \*\*Step 5.1: Create RBAC for Beyla\*\*

\`\`\`bash

\# Create beyla-rbac.yml

cat > beyla-rbac.yml << 'EOF'

apiVersion: v1

kind: ServiceAccount

metadata:

namespace: default

name: beyla

\---

apiVersion: rbac.authorization.k8s.io/v1

kind: ClusterRole

metadata:

name: beyla

rules:

\- apiGroups: \["apps"\]

resources: \["replicasets"\]

verbs: \["list", "watch"\]

\- apiGroups: \[""\]

resources: \["pods", "services", "nodes"\]

verbs: \["list", "watch"\]

\---

apiVersion: rbac.authorization.k8s.io/v1

kind: ClusterRoleBinding

metadata:

name: beyla

subjects:

\- kind: ServiceAccount

name: beyla

namespace: default

roleRef:

apiGroup: rbac.authorization.k8s.io

kind: ClusterRole

name: beyla

EOF

\# Apply

kubectl apply -f beyla-rbac.yml

\`\`\`

\## \*\*Step 5.2: Deploy Your Java App with Beyla Sidecar\*\*

\`\`\`bash

\# Create myapp-deployment.yml

cat > myapp-deployment.yml << 'EOF'

apiVersion: apps/v1

kind: Deployment

metadata:

name: myapp

namespace: default

spec:

replicas: 2

selector:

matchLabels:

app: myapp

template:

metadata:

labels:

app: myapp

spec:

serviceAccountName: beyla

containers:

\- name: myapp

image: myapp:latest

imagePullPolicy: IfNotPresent

ports:

\- containerPort: 8080

\- name: beyla

image: grafana/beyla:latest

securityContext:

privileged: true

env:

\- name: BEYLA\_OPEN\_PORT

value: "8080"

\- name: OTEL\_EXPORTER\_OTLP\_ENDPOINT

value: "http://tempo.beyla.svc.cluster.local:4317"

\- name: BEYLA\_KUBE\_METADATA\_ENABLE

value: "true"

\- name: BEYLA\_PROMETHEUS\_METRICS\_ENABLE

value: "true"

\- name: BEYLA\_PROMETHEUS\_METRICS\_PORT

value: "9998"

volumeMounts:

\- name: var-run-beyla

mountPath: /var/run/beyla

volumes:

\- name: var-run-beyla

emptyDir: {}

\---

apiVersion: v1

kind: Service

metadata:

name: myapp-service

spec:

selector:

app: myapp

ports:

\- protocol: TCP

port: 8080

targetPort: 8080

type: NodePort

EOF

\# Apply

kubectl apply -f myapp-deployment.yml

\`\`\`

\---

\# ğŸ¯ \*\*PHASE 6: CONFIGURE ACCESS\*\*

\## \*\*Step 6.1: Get External IP and Ports\*\*

\`\`\`bash

\# On MASTER node

\# 1. Get master node external IP

MASTER\_IP=$(curl -s http://metadata.google.internal/computeMetadata/v1/instance/network-interfaces/0/access-configs/0/external-ip -H "Metadata-Flavor: Google")

\# 2. Get NodePorts

GRAFANA\_PORT=$(kubectl get svc -n beyla grafana -o jsonpath='{.spec.ports\[0\].nodePort}')

APP\_PORT=$(kubectl get svc myapp-service -o jsonpath='{.spec.ports\[0\].nodePort}')

echo "========================================"

echo "âœ… SETUP COMPLETE!"

echo "========================================"

echo ""

echo "ğŸ“Š Grafana Dashboard:"

echo " URL: http://$MASTER\_IP:$GRAFANA\_PORT"

echo " Username: admin"

echo " Password: admin"

echo ""

echo "ğŸš€ Your Java Application:"

echo " URL: http://$MASTER\_IP:$APP\_PORT"

echo ""

echo "ğŸ”§ To configure Grafana:"

echo " 1. Go to http://$MASTER\_IP:$GRAFANA\_PORT"

echo " 2. Login with admin/admin"

echo " 3. Go to Connections â†’ Data sources"

echo " 4. Add 'Tempo' data source"

echo " 5. Set URL: http://tempo:3200"

echo " 6. Save & Test"

echo ""

echo "ğŸ“¡ To generate traces:"

echo " for i in {1..20}; do curl http://$MASTER\_IP:$APP\_PORT; sleep 2; done"

echo "========================================"

\`\`\`

\## \*\*Step 6.2: Open GCP Firewall\*\*

\`\`\`bash

\# Open NodePort range

gcloud compute firewall-rules create allow-nodeports \\

\--allow tcp:30000-32767 \\

\--source-ranges=0.0.0.0/0

\`\`\`

\---

\# ğŸ¯ \*\*PHASE 7: FINAL VERIFICATION\*\*

\## \*\*Step 7.1: Run Complete Status Check\*\*

\`\`\`bash

\# On MASTER node

echo "=== FINAL VERIFICATION ==="

echo ""

echo "1. Cluster Nodes:"

kubectl get nodes

echo ""

echo "2. All Pods Status:"

kubectl get pods -A

echo ""

echo "3. Your Application:"

kubectl get pods -l app=myapp

echo ""

echo "4. Beyla Logs (check instrumentation):"

kubectl logs -l app=myapp -c beyla --tail=3

echo ""

echo "5. Services:"

kubectl get svc -A

echo ""

echo "=== VERIFICATION COMPLETE ==="

\`\`\`

\## \*\*Step 7.2: Test Everything\*\*

\`\`\`bash

\# 1. Test your app

curl -v http://$MASTER\_IP:$APP\_PORT

\# 2. Generate traffic for traces

for i in {1..10}; do

curl -s http://$MASTER\_IP:$APP\_PORT > /dev/null && echo "âœ“ Request $i" || echo "âœ— Request $i"

sleep 2

done

\# 3. Check Grafana is accessible

curl -I http://$MASTER\_IP:$GRAFANA\_PORT

\`\`\`

\---

\# ğŸš¨ \*\*TROUBLESHOOTING COMMANDS\*\*

\## \*\*If pods stuck in ContainerCreating:\*\*

\`\`\`bash

kubectl describe pod <pod-name>

kubectl logs <pod-name> --previous

\`\`\`

\## \*\*If images not pulling:\*\*

\`\`\`bash

\# Manually pull on each node

sudo docker pull grafana/beyla:latest

sudo docker pull grafana/tempo:2.3.0

sudo docker pull grafana/grafana:latest

\`\`\`

\## \*\*If network issues:\*\*

\`\`\`bash

\# Check Calico

kubectl get pods -n calico-system

kubectl logs -n calico-system --all-containers

\`\`\`

\## \*\*If nodes not joining:\*\*

\`\`\`bash

\# On worker nodes

sudo kubeadm reset

sudo systemctl restart docker

sudo systemctl restart kubelet

\# Then join again

\`\`\`

\---

\# âœ… \*\*SUCCESS CRITERIA\*\*

1\. âœ… \*\*kubectl get nodes\*\* shows all 3 nodes as \*\*Ready\*\*

2\. âœ… \*\*kubectl get pods -A\*\* shows all pods as \*\*Running\*\*

3\. âœ… Can access \*\*Grafana\*\* at \`http://<MASTER\_IP>:<PORT>\`

4\. âœ… Can access \*\*Your App\*\* at \`http://<MASTER\_IP>:<PORT>\`

5\. âœ… \*\*Beyla logs\*\* show "instrumenting process"

6\. âœ… \*\*Traces appear\*\* in Grafana Tempo

\---

\# ğŸ“ \*\*IF STUCK - RUN THESE DIAGNOSTICS\*\*

\`\`\`bash

\# 1. Cluster health

kubectl get componentstatuses

\# 2. Pod events

kubectl get events --sort-by='.lastTimestamp'

\# 3. Node details

kubectl describe nodes

\# 4. Service endpoints

kubectl get endpoints -A

\`\`\`

\---

\*\*FOLLOW THIS GUIDE STEP-BY-STEP FROM PHASE 1\*\*

\*\*DO NOT SKIP ANY STEP\*\*

\*\*COPY-PASTE COMMANDS EXACTLY\*\*

Good luck! You can do this! ğŸš€

\*\*Start with Phase 1 on ALL 3 nodes, then move to Phase 2 on Master only.\*\*
